---
phase: 02-extraction-pipeline
plan: 03
type: execute
wave: 2
depends_on: ["02-02"]
files_modified: [app/core/extraction/grounding.py, app/core/extraction/prompts/grounding.py]
autonomous: true

must_haves:
  truths:
    - "Grounding test extractor returns structured resistance measurements"
    - "Equipment TAG and serial number are extracted with confidence"
    - "Measurements include units (ohms)"
  artifacts:
    - path: "app/core/extraction/grounding.py"
      provides: "Grounding test extractor"
      contains: "class GroundingExtractor"
    - path: "app/core/extraction/prompts/grounding.py"
      provides: "Grounding extraction prompt"
      min_lines: 30
  key_links:
    - from: "app/core/extraction/grounding.py"
      to: "app/core/extraction/base.py"
      via: "extends BaseExtractor"
      pattern: "BaseExtractor"
---

<objective>
Create grounding test report extractor for resistance measurements and equipment identification.

Purpose: Extract structured data from grounding/earthing test reports including resistance values, equipment info, and test conditions.

Output: GroundingExtractor that returns validated grounding test data with field-level confidence.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-extraction-pipeline/02-02-SUMMARY.md

Requirements this plan addresses:
- EXTR-01: System extracts structured data from Grounding test reports
- EXTR-04: System extracts equipment identification (TAG, serial number, type)
- EXTR-05: System extracts test measurements with units
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create grounding extraction schema</name>
  <files>app/core/extraction/grounding.py</files>
  <action>
Create Pydantic schemas for grounding test extraction.

app/core/extraction/grounding.py:
- Import from .schemas import FieldConfidence, BaseExtractionResult, EquipmentInfo, CalibrationInfo

class GroundingMeasurement(BaseModel):
  """Single grounding resistance measurement."""
  test_point: FieldConfidence  # e.g., "Main Ground Bus", "Equipment Ground"
  resistance_value: FieldConfidence  # numeric value
  resistance_unit: str = "ohms"  # always ohms for grounding
  test_method: FieldConfidence | None = None  # e.g., "Fall of Potential", "3-Point"
  soil_conditions: FieldConfidence | None = None
  temperature: FieldConfidence | None = None
  humidity: FieldConfidence | None = None

class GroundingTestConditions(BaseModel):
  """Test conditions during grounding measurement."""
  test_date: FieldConfidence
  tester_name: FieldConfidence | None = None
  weather_conditions: FieldConfidence | None = None
  instrument_model: FieldConfidence | None = None
  instrument_serial: FieldConfidence | None = None

class GroundingExtractionResult(BaseExtractionResult):
  """Complete grounding test extraction result."""
  equipment: EquipmentInfo
  calibration: CalibrationInfo | None = None
  test_conditions: GroundingTestConditions
  measurements: list[GroundingMeasurement]

  # Derived fields
  min_resistance: float | None = None
  max_resistance: float | None = None
  avg_resistance: float | None = None

  def model_post_init(self, __context):
      """Calculate derived fields after initialization."""
      if self.measurements:
          values = [m.resistance_value.value for m in self.measurements
                   if isinstance(m.resistance_value.value, (int, float))]
          if values:
              self.min_resistance = min(values)
              self.max_resistance = max(values)
              self.avg_resistance = sum(values) / len(values)
  </action>
  <verify>python3 -c "from app.core.extraction.grounding import GroundingExtractionResult"</verify>
  <done>Grounding extraction schema with measurements and equipment info</done>
</task>

<task type="auto">
  <name>Task 2: Create grounding extraction prompt</name>
  <files>app/core/extraction/prompts/__init__.py, app/core/extraction/prompts/grounding.py</files>
  <action>
Create the system prompt for grounding test extraction.

app/core/extraction/prompts/grounding.py:

GROUNDING_EXTRACTION_PROMPT = '''
You are an expert electrical engineer extracting data from grounding/earthing test reports.

Extract the following information with high accuracy:

## Equipment Information
- Equipment TAG (identifier on the equipment label)
- Serial number
- Equipment type (e.g., PANEL, UPS, ATS, GEN, XFMR)
- Manufacturer and model if visible

## Calibration Information
- Calibration certificate number
- Calibration date
- Expiration date (CRITICAL - must be extracted)
- Calibration laboratory

## Test Conditions
- Test date
- Tester name
- Weather conditions
- Instrument model and serial number

## Measurements
For each grounding test point:
- Test point description (e.g., "Main Ground Bus", "Equipment Ground Rod")
- Resistance value in OHMS
- Test method used (e.g., "Fall of Potential", "3-Point", "Clamp-on")
- Soil conditions if mentioned
- Temperature and humidity if recorded

## Confidence Scoring
For each extracted field, provide a confidence score (0.0 to 1.0):
- 1.0: Value is clearly visible and unambiguous
- 0.8-0.9: Value is visible but slightly unclear
- 0.6-0.7: Value is partially obscured or estimated
- 0.3-0.5: Value is guessed from context
- 0.0-0.2: Value is not found or unreliable

Also extract the source_text - the exact text from the document that contains the value.

## Critical Rules
1. Resistance values MUST include the unit (ohms)
2. Dates MUST be in ISO format (YYYY-MM-DD)
3. Do NOT invent or assume values - leave as null if not found
4. Flag any anomalies (e.g., resistance > 10 ohms for main ground)
'''

app/core/extraction/prompts/__init__.py:
- Export GROUNDING_EXTRACTION_PROMPT
  </action>
  <verify>python3 -c "from app.core.extraction.prompts import GROUNDING_EXTRACTION_PROMPT"</verify>
  <done>Grounding extraction prompt with detailed instructions</done>
</task>

<task type="auto">
  <name>Task 3: Create grounding extractor class</name>
  <files>app/core/extraction/grounding.py</files>
  <action>
Add GroundingExtractor class to grounding.py.

class GroundingExtractor(BaseExtractor):
  """Extractor for grounding/earthing test reports."""

  @property
  def test_type(self) -> str:
      return "grounding"

  @property
  def system_prompt(self) -> str:
      from .prompts import GROUNDING_EXTRACTION_PROMPT
      return GROUNDING_EXTRACTION_PROMPT

  def get_response_model(self) -> type[GroundingExtractionResult]:
      return GroundingExtractionResult

  def _check_needs_review(self, result: GroundingExtractionResult) -> bool:
      """Check if grounding extraction needs review."""
      # Check overall confidence
      if result.overall_confidence < self.CONFIDENCE_THRESHOLD:
          return True

      # Check critical fields
      if result.equipment.equipment_tag.confidence < self.CONFIDENCE_THRESHOLD:
          return True

      # Check if any measurement has low confidence
      for m in result.measurements:
          if m.resistance_value.confidence < self.CONFIDENCE_THRESHOLD:
              return True

      # Check calibration expiration
      if result.calibration and result.calibration.expiration_date.confidence < 0.8:
          return True

      return False

Update app/core/extraction/__init__.py to export GroundingExtractor.
  </action>
  <verify>python3 -c "from app.core.extraction import GroundingExtractor"</verify>
  <done>GroundingExtractor ready for grounding test report processing</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] GroundingExtractionResult schema is complete
- [ ] Prompt includes all required extraction fields
- [ ] GroundingExtractor inherits from BaseExtractor
- [ ] Confidence checking covers critical fields
- [ ] Derived fields (min/max/avg) are calculated
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Extractor handles typical grounding report format
- Field-level confidence is tracked
</success_criteria>

<output>
After completion, create `.planning/phases/02-extraction-pipeline/02-03-SUMMARY.md`
</output>
