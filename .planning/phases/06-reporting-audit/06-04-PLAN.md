---
phase: 06-reporting-audit
plan: 04
type: execute
wave: 2
depends_on: ["06-03"]
files_modified:
  - app/api/audit.py
  - app/api/schemas.py
  - app/main.py
  - app/tests/api/test_audit.py
autonomous: true

must_haves:
  truths:
    - "User can retrieve audit trail via GET /api/analyses/{id}/audit"
    - "Audit trail shows all events in chronological order"
    - "Each event includes timestamp, type, and relevant details"
    - "Endpoint requires authentication and ownership"
  artifacts:
    - path: "app/api/audit.py"
      provides: "Audit trail endpoint"
      exports: ["router"]
    - path: "app/api/schemas.py"
      provides: "AuditLogResponse schema"
      contains: "AuditLogResponse"
  key_links:
    - from: "app/api/audit.py"
      to: "AuditService.get_audit_trail"
      via: "service call"
      pattern: "get_audit_trail"
---

<objective>
Create audit trail API endpoint for compliance verification.

Purpose: Complete AUDT-06 - users can retrieve the complete audit trail for any analysis they own. Enables engineers to verify HOW each finding was generated.

Output: Protected endpoint GET /api/analyses/{analysis_id}/audit returning chronological event list.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-reporting-audit/06-03-PLAN.md

# API patterns
@app/api/analyses.py
@app/api/schemas.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add audit response schemas</name>
  <files>app/api/schemas.py</files>
  <action>
Add to app/api/schemas.py:

1. AuditEventResponse schema:
   - id: UUID
   - event_type: str
   - event_timestamp: datetime
   - details: dict[str, Any] | None
   - model_version: str | None
   - prompt_version: str | None
   - confidence_score: float | None
   - rule_id: str | None

2. AuditTrailResponse schema:
   - analysis_id: UUID
   - event_count: int
   - events: list[AuditEventResponse]

Both with model_config = {"from_attributes": True}
  </action>
  <verify>python -c "from app.api.schemas import AuditEventResponse, AuditTrailResponse; print('OK')"</verify>
  <done>Audit response schemas added</done>
</task>

<task type="auto">
  <name>Task 2: Create audit trail endpoint</name>
  <files>app/api/audit.py</files>
  <action>
Create app/api/audit.py:

1. Router with prefix="/api/analyses" and tags=["audit"]

2. GET /{analysis_id}/audit endpoint:
   - Parameters: analysis_id: UUID
   - Dependencies: DbSession, CurrentUser
   - Process:
     a. Import and reuse verify_analysis_ownership from app.api.analyses
     b. Call AuditService.get_audit_trail(db, analysis_id)
     c. Convert AuditLog records to AuditEventResponse
     d. Return AuditTrailResponse with event list
   - Responses:
     - 200: AuditTrailResponse
     - 401: Not authenticated
     - 403: Access denied
     - 404: Analysis not found

3. Optional: Add pagination with skip/limit query params (default limit=100)
   - If events > limit, return most recent (ordered by timestamp desc, then reversed)
  </action>
  <verify>python -c "from app.api.audit import router; print('OK')"</verify>
  <done>Audit trail endpoint created</done>
</task>

<task type="auto">
  <name>Task 3: Register audit router in main app</name>
  <files>app/main.py</files>
  <action>
1. Import: from app.api.audit import router as audit_router
2. Add audit_router to app.include_router() calls
3. Add "audit" tag to OpenAPI tags list with description "Audit trail retrieval for compliance verification"

Keep imports grouped with other API routers.
  </action>
  <verify>python -c "from app.main import app; print([r.path for r in app.routes if 'audit' in r.path])"</verify>
  <done>Audit router registered</done>
</task>

<task type="auto">
  <name>Task 4: Add integration tests for audit endpoint</name>
  <files>app/tests/api/test_audit.py</files>
  <action>
Create integration tests:

1. test_get_audit_trail_requires_auth:
   - GET /api/analyses/{uuid}/audit without token
   - Assert 401

2. test_get_audit_trail_returns_events:
   - Create analysis with audit logs
   - GET with valid auth
   - Assert 200
   - Assert response contains event_count and events list

3. test_get_audit_trail_chronological_order:
   - Create multiple audit logs
   - GET audit trail
   - Assert events are ordered by timestamp (ascending = chronological)

4. test_get_audit_trail_not_found:
   - GET /api/analyses/{random_uuid}/audit with auth
   - Assert 404

5. test_get_audit_trail_wrong_user:
   - Create analysis owned by user A
   - GET with token for user B
   - Assert 403

6. test_audit_event_includes_all_fields:
   - Create audit log with model_version, prompt_version, confidence_score, rule_id
   - GET audit trail
   - Assert all fields present in response

Use fixtures from conftest.py. Focus tests on auth and response format (some may need mocking due to SQLite limitations).
  </action>
  <verify>cd /home/xande && python -m pytest app/tests/api/test_audit.py -v</verify>
  <done>6 integration tests passing</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -c "from app.api.audit import router"` works
- [ ] Audit endpoint appears in OpenAPI docs
- [ ] `python -m pytest app/tests/api/test_audit.py -v` passes all tests
- [ ] curl test returns audit trail JSON (manual if possible)
</verification>

<success_criteria>
- All tasks completed
- GET /api/analyses/{id}/audit endpoint functional
- Endpoint requires authentication and ownership
- Returns chronological event list
- All audit event fields exposed in response
- 6 integration tests passing
</success_criteria>

<output>
After completion, create `.planning/phases/06-reporting-audit/06-04-SUMMARY.md`
</output>
